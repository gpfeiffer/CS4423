{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS4423 - Networks\n",
    "Prof. GÃ¶tz Pfeiffer<br />\n",
    "School of Mathematics, Statistics and Applied Mathematics<br />\n",
    "NUI Galway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Power Laws and Scale-Free Graphs\n",
    "\n",
    "# Lecture 19:  Hubs and Authorities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Degree vs. Out-Degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall **in-degree** and **out-degree centrality**:\n",
    "$$\n",
    "c_i^{D^{\\text{in}}} = k_i^{\\text{in}} = \\sum_{j=1}^n a_{ij},\n",
    "\\quad\n",
    "c_i^{D^{\\text{out}}} = k_i^{\\text{out}} = \\sum_{j=1}^n a_{ji},\n",
    "$$\n",
    "where $A = (a_{ij})$ is the adjacency matrix of a directed graph\n",
    "$G = (X, E)$ ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the corresponding **eigenvector centralities**:\n",
    "$$\n",
    "A c^{E^{\\text{in}}} = \\lambda c^{E^{\\text{in}}},\n",
    "\\quad\n",
    "A^{T} c^{E^{\\text{out}}} = \\lambda c^{E^{\\text{out}}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hub Centrality and Authority Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a network of nodes connected by directed edges, each node\n",
    "plays two different roles, one as a receiver of links, and one as\n",
    "a sender of links.  A first measure of importance, or recognition, of\n",
    "a node in this network might be the number of\n",
    "links it receives, i.e., its **in-degree** in the underlying graph.\n",
    "If in a collection of web pages relating to a search query on the\n",
    "subject of \"networks\", say, a particular page receives a high number\n",
    "of links, this page might count as an **authority** on that subject,\n",
    "with **authority score** measured by its in-degree.\n",
    "\n",
    "In turn, the web pages linking to an authority in some sense know\n",
    "where to find valuable information and thus serve as good \"lists\" for\n",
    "the subject.\n",
    "A high value list is called a **hub** for this query.\n",
    "It makes sense to measure the value of a page as list in\n",
    "terms of the values of the pages it points at, by assigning to its\n",
    "**hub score** the sum of the authority scores of the pages it points\n",
    "at.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hubs](images/hubs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now\n",
    "the authority score of a page  could take the hub scores\n",
    "of the list pages into account, by using the sum of the hub scores\n",
    "of the pages that point at it as an updated authority score.\n",
    "\n",
    "Then again, applying the **Principle of Repeated Improvement**,\n",
    "the hub scores can be updated on the basis of the new authority scores,\n",
    "and so on.\n",
    "\n",
    "This suggests a ranking procedure that tries to estimate, for each page $p$,\n",
    "its value as an authority and its value as a hub in the form\n",
    "of numerical scores, $a(p)$ and $h(p)$.\n",
    "\n",
    "Starting off with values all equal to $1$, the estimates are updated\n",
    "by applying the following two rules in an alternating fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Authority Update Rule:**\n",
    "For each page $p$, update $a(p)$\n",
    "to be the sum of the hub scores of all the pages pointing to it.\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Hub Update Rule:**\n",
    "For each page $p$,\n",
    "update $h(p)$\n",
    "to be the sum of the authority\n",
    "scores of all the pages\n",
    "that it points to.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep the numbers from growing too large,\n",
    "score vectors should be **normalized** after each step,\n",
    "in a way that  replaces $h$ by a scalar multiple $\\hat{h} = sh$\n",
    "so that the entries in $\\hat{h}$ add up to $100$, say,\n",
    "representing relative percentage values,\n",
    "similarly for $a$.\n",
    "\n",
    "After a number of iterations, the values $a(p)$ and\n",
    "$h(p)$ stabilize, in the sense that further applications of\n",
    "the update rules do not yield essentially better relative estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.**\n",
    "Continuing the example above ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(range(1,10)) + [\"A%s\" % (i+1) for i in range(7)]\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [\n",
    "    (1,\"A1\"),(2,\"A1\"),(3,\"A1\"),(3,\"A2\"),(4,\"A2\"),(5,\"A3\"),\n",
    "    (5,\"A5\"),(6,\"A2\"),(6,\"A4\"),(7,\"A4\"),(7,\"A5\"),(8,\"A4\"),\n",
    "    (8,\"A5\"),(8,\"A6\"),(8,\"A7\"),(9,\"A5\"),(9,\"A6\"),(9,\"A7\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.circular_layout(G)\n",
    "for i in [1,2,3,4]:\n",
    "    j = 10 - i\n",
    "    pos[i], pos[j] = pos[j], pos[i]\n",
    "colors = 9 * ['y'] + 7 * ['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, with_labels=True, node_color=colors, pos=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use dictionaries, with nodes as keys and hub or authority scores as values.\n",
    "Here's a way to normalize such a record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(d):\n",
    "    s = sum(d.values())\n",
    "    return { k: 100/s*v for k, v in d.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, all scores are set to $1$ (and then normalized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs = normalized({ x : 1 for x in G })\n",
    "auth = normalized({ x : 1 for x in G })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update rules can then be implemented as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HubsUpdate(G, auth):\n",
    "    h = { x: 0 for x in G }\n",
    "    for x in G:\n",
    "        for y in G.successors(x):\n",
    "            h[x] += auth[y]\n",
    "    return normalized(h)\n",
    "\n",
    "def AuthUpdate(G, hubs):\n",
    "    a = { x: 0 for x in G }\n",
    "    for x in G:\n",
    "        for y in G.successors(x):\n",
    "            a[y] += hubs[x]\n",
    "    return normalized(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the rules. alternating between the two, say 10 times, and observe how the scores stabilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10):\n",
    "    auth = AuthUpdate(G, hubs)\n",
    "    print(\"auth= \", auth)\n",
    "    hubs = HubsUpdate(G, auth)\n",
    "    print(\"hubs = \", hubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in one `python` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HubsAuth(G, k):\n",
    "    hubs = normalized({ x : 1 for x in G })\n",
    "    auth = normalized({ x : 1 for x in G })\n",
    "    for i in range(k):\n",
    "        auth = AuthUpdate(G, hubs)\n",
    "        hubs = HubsUpdate(G, auth)\n",
    "    \n",
    "    return hubs, auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs, auth = HubsAuth(G, 10)\n",
    "hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's apply this to a random directed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = 80, 120\n",
    "G = nx.gnm_random_graph(n, m, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubs, auth = HubsAuth(G, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the top and the bottom 10 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(k,auth[k]) for k in sorted(auth, key=auth.get, reverse=True)][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(k,auth[k]) for k in sorted(auth, key=auth.get)][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(k, hubs[k]) for k in sorted(hubs, key=hubs.get, reverse=True)][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(k, hubs[k]) for k in sorted(hubs, key=hubs.get)][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of matrix algebra this effect can be described as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Spectral Analysis of Hubs and Authorities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $M = (m_{ij})$ be the **adjacency matrix** of the directed graph\n",
    "$G = (X, E)$\n",
    "that is $m_{ij} = 1$ if $x_j \\to x_i$ and $m_{ij} = 0$ otherwise,\n",
    "where $X = \\{x_1, \\dots, x_n\\}$.\n",
    "\n",
    "We write $h = (h_1, \\dots, h_n)$ for a list of hub scores, with $h_i = h(x_i)$,\n",
    "the hub score of node $x_i$.  Similarly, we write $a = (a_1, \\dots, a_l)$ for\n",
    "a list of authority scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **hub update rule** can now be expressed as\n",
    "a **matrix multiplication**:\n",
    "$$\n",
    "h \\gets M^T a\n",
    "$$\n",
    "and similarly, the **authority update rule**, using the transpose of the matrix $M$:\n",
    "$$\n",
    "a \\gets M h\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying two steps of the procedure at once yields update rules\n",
    "$$\n",
    "  h \\gets M^T M h\n",
    "$$\n",
    "and\n",
    "$$\n",
    "  a \\gets M M^T \\, a\n",
    "$$\n",
    "for $h$ and $a$, respectively.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the limit**, one expects\n",
    "to get vectors $h^{\\ast}$ and $a^{\\ast}$ whose directions do not change\n",
    "under the latter rules, i.e.,\n",
    "$$\n",
    "  (M^T M) h^{\\ast} = c h^{\\ast}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "  (M M^T) a^{\\ast} = d a^{\\ast}\n",
    "$$\n",
    "for certain constants $c$ and $d$, meaning that $h^{\\ast}$ and $a^{\\ast}$\n",
    "are **eigenvectors** for the matrices $M^T M$ and $M M^T$,\n",
    "respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fact that $M^T M$ and $M M^T$ are **symmetric** matrices\n",
    "($(M^T M)^T = M^T (M^T)^T = M^T M$),\n",
    "it can indeed be shown that any sequence of hub score vectors\n",
    "$h$ under repeated application of the above update rule\n",
    "converges to a real-valued eigenvector $h^{\\ast}$ of $M M^T$ for the real eigenvalue $c$.\n",
    "The argument uses the [Spectral Theorem](https://en.wikipedia.org/wiki/Spectral_theorem)\n",
    "for [real symmetric matrices](https://en.wikipedia.org/wiki/Symmetric_matrix#Real_symmetric_matrices).\n",
    "\n",
    "\n",
    "A similar result exists for any sequence of authority score vectors $a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank\n",
    "\n",
    "A simpler model of endorsement for web pages involves only\n",
    "one numerical value $r(p)$ per page $p$, built on the principle that\n",
    "**a page is as important as the pages linking to it**.\n",
    "As before, these importance values can be obtained by\n",
    "repeatedly applying a suitable update rule to a set of current values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, PageRank is computed as follows.\n",
    "\n",
    "* If the network has $n$ nodes, each page $p$ receives an initial PageRank\n",
    "of $r(p) = 1/n$.\n",
    "\n",
    "* Choose a number of steps, $k$.\n",
    "\n",
    "* Perform the following update rule $k$ times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" markdown=\"1\">\n",
    "\n",
    "**Basic PageRank Update Rule:**\n",
    "Each page divides its current PageRank by the number of\n",
    "pages it links to, and passes this value on to those pages.\n",
    "In this way, each page updates its PageRank to be the sum of\n",
    "all the shares it receives from the pages linking to it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in each step, the total PageRank of all nodes is maintained\n",
    "(each node splits its PageRank into equal parts and passes this on,\n",
    "nothing is lost or gained overall), there is no need for normalization.\n",
    "\n",
    "After a number of steps, the PageRank values of the individual nodes \n",
    "stabilize.  These values form an equilibrium in the sense that\n",
    "another application of the update rule will produce exactly the same\n",
    "values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.**  The following graph represents\n",
    "a network of $8$ web pages with hyperlinks.\n",
    "\n",
    "![paherank](images/pagerank.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows how the initial PageRank\n",
    "of $\\frac18$ of each page is updated under six iterations\n",
    "of the basic PageRank update rule\n",
    "and, in the bottom row, the limit values.\n",
    "\n",
    "![pagerank-p](images/pagerank-p.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a slightly larger example, let's implement this algorithm as a `python` program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = 80, 120\n",
    "G = nx.gnm_random_graph(n, m, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.out_degree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm doesn't work if there is a node $x$ with no successors in $G$. (Why?)\n",
    "So for now, let's add some random edges to make sure each node $x$ has out-degree at least $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for x in G:\n",
    "    y = x\n",
    "    while y == x:\n",
    "        y = random.randrange(n)\n",
    "    G.add_edge(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PageRank(G, k):\n",
    "    n = G.order()\n",
    "    r = { x: 1/n for x in G }\n",
    "    for i in range(k):\n",
    "        s = { x : 0 for x in G }\n",
    "        for x in G:\n",
    "            l = G.out_degree(x)\n",
    "            v = r[x]/l\n",
    "            for y in G.successors(x):\n",
    "                s[y] += v\n",
    "        r = s\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "pr = PageRank(G, k)\n",
    "[(k,pr[k]) for k in sorted(pr, key=pr.get)][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k,pr[k]) for k in sorted(pr, key=pr.get, reverse=True)][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of matrix algebra this effect can be described as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Spectral Analysis of PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use a **variant of the adjacency matrix** $A$ of the directed graph $G = (X, V)$.\n",
    "\n",
    "Let $N$ be the $n \\times n$ matrix with entries $N_{ij} = 0$\n",
    "if node $x_j$ is not linked to node $x_i$ (as for the adjacency matrix $A$).\n",
    "And when $x_j \\to x_i$, then set $N_{ij} = 1/l_j$, \n",
    "where $l_j$ is the number of links out of $x_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write $r = (r_1, \\dots, r_n)$ for the list of PageRank values of the nodes\n",
    "$X = \\{x_1, \\dots, x_n\\}$.  Then the **basic PageRank update rule**\n",
    "can be expressed as **matrix multiplication**:\n",
    "$$\n",
    "r \\gets N \\,r.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown that repeated application of the basic PageRank update rule\n",
    "lets the PageRank values converge towards a vector $r^{\\ast}$ with the property\n",
    "$$\n",
    "N\\, r^{\\ast} = r^{\\ast},\n",
    "$$\n",
    "that is, $r^{\\ast}$ is an **eigenvector** of $N for the eigenvalue $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument uses the [Perron-Frobenius Theorem](https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem) which we have seen before.  Recall that, for a matrix in which all entries are non-negative (such as the matrix $N^T$) the theorem guarantees the existence of a **real eigenvalue**\n",
    "with corresponding **eigenvector having non-negative entries**.\n",
    "(Not every matrix with real entries has this property.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `python`\n",
    "\n",
    "* `sorted`: [[doc]](https://docs.python.org/3/library/functions.html#sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `random`\n",
    "\n",
    "* `randrange` vs. `randint`: [[doc]](https://docs.python.org/3/library/random.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `networkx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `DiGraph`: [[doc]](https://networkx.github.io/documentation/stable/reference/classes/digraph.html)\n",
    "\n",
    "\n",
    "* `circular_layout`: [[doc]](https://networkx.github.io/documentation/stable/reference/generated/networkx.drawing.layout.circular_layout.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It might be tempting to combine the hubs and authorities update rules into a single `for` loop.\n",
    "Why is this not a good idea?\n",
    "\n",
    "1. Create a random $G(n, m)$ graph (with $n = 80$ and $m = 100$, say) and identify its Bow-Tie components\n",
    "(Giant SCC, IN, OUT, tendrils and tubes).  Then compute Hubs and Authority centralities to identify\n",
    "strong hubs and heavy authorities.  Which Bow-Tie components do hubs and authorities prefer?\n",
    "\n",
    "1. Create a random $G(n, m)$ graph (with $n = 80$ and $m = 100$, say) and \n",
    "complete the graph with further random edges so that each node has out-degree at least $1$.\n",
    "Identify the graph's Bow-Tie components\n",
    "(Giant SCC, IN, OUT, tendrils and tubes).  Then compute PageRank centralities to identify\n",
    "important pages.  Which Bow-Tie components do these pages prefer?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
